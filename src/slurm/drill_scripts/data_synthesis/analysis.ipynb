{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The following code analyzes the viable_patches_json file. The points of analysis are described below. The primary tool for this analysis is pydriller.\n",
    "\n",
    "1. Total size of the cloned repos\n",
    "2. Total number of vulnerability inducing commits (vuln commits) found & not found\n",
    "3. Average number of vuln commits to patch commit (or fix)\n",
    "4. Average number of months between a vuln commit\n",
    "5. Percentage of vulns where the vuln commit and fix were made by the same person\n",
    "\n",
    "\n",
    "##### Sources\n",
    "- @inbook{PyDriller,\n",
    "    title = \"PyDriller: Python Framework for Mining Software Repositories\",\n",
    "    abstract = \"Software repositories contain historical and valuable information about the overall development of software systems. Mining software repositories (MSR) is nowadays considered one of the most interesting growing fields within software engineering. MSR focuses on extracting and analyzing data available in software repositories to uncover interesting, useful, and actionable information about the system. Even though MSR plays an important role in software engineering research, few tools have been created and made public to support developers in extracting information from Git repository. In this paper, we present PyDriller, a Python Framework that eases the process of mining Git. We compare our tool against the state-of-the-art Python Framework GitPython, demonstrating that PyDriller can achieve the same results with, on average, 50% less LOC and significantly lower complexity.URL: https://github.com/ishepard/pydrillerMaterials: https://doi.org/10.5281/zenodo.1327363Pre-print: https://doi.org/10.5281/zenodo.1327411\",\n",
    "    author = \"Spadini, Davide and Aniche, Maur√≠cio and Bacchelli, Alberto\",\n",
    "    year = \"2018\",\n",
    "    doi = \"10.1145/3236024.3264598\",\n",
    "    booktitle = \"The 26th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE)\",\n",
    "    }\n",
    "\n",
    "##### Author @Trust-Worthy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading in the results from the patch_vuln_match.json file and processing objects according to JSONL standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           cve_id                     repo  \\\n",
      "0   CVE-1999-0199             bminor/glibc   \n",
      "1   CVE-1999-0731         KDE/kde1-kdebase   \n",
      "2   CVE-2002-2443                krb5/krb5   \n",
      "3  CVE-2005-10002  wp-plugins/secure-files   \n",
      "4  CVE-2005-10003      mikexstudios/xcomic   \n",
      "\n",
      "                               patch_commit  \\\n",
      "0  2864e767053317538feafa815046fff89e5a16be   \n",
      "1  04906bd5de2f220bf100b605dad37b4a1d9a91a6   \n",
      "2  cf1a0c411b2668c57c41e9c4efd15ba17b6b322c   \n",
      "3  cab025e5fc2bcdad8032d833ebc38e6bd2a13c92   \n",
      "4  6ed8e3cc336e29f09c7e791863d0559939da98bf   \n",
      "\n",
      "                                        vuln_commits  \\\n",
      "0  [dc5efe83c0252ad45337ab98eff6c26fdb29b0a9, 27a...   \n",
      "1                                                 []   \n",
      "2  [e88f857c3680ea395c0bed6a82862d8ea1177221, 438...   \n",
      "3         [b1afc063fd49cfb875e1c6f591543ebff6649469]   \n",
      "4                                                 []   \n",
      "\n",
      "                                          vuln_files  \n",
      "0  [elf/dl-load.c, manual/search.texi, misc/syslo...  \n",
      "1                                                 []  \n",
      "2                        [src/kadmin/server/schpw.c]  \n",
      "3                                 [secure-files.php]  \n",
      "4                                                 []  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jsonlines    \n",
    "\n",
    "json_path:str = \"../production_ready/patch_vuln_match.jsonl\"\n",
    "\n",
    "data: list[object] = []\n",
    "\n",
    "with jsonlines.open(json_path) as reader:\n",
    "\n",
    "    data = [entry for entry in reader]\n",
    "\n",
    "# Convert the list of dictionaries into a pandas DataFrame\n",
    "patch_vuln_df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Define a function to extract the file paths and commits\n",
    "def extract_vuln_files_commits(vuln_commits):\n",
    "    if vuln_commits:\n",
    "        files = list(vuln_commits.keys())\n",
    "        commits = [commit for commits in vuln_commits.values() for commit in commits]\n",
    "        return pd.Series([files, commits])\n",
    "    else:\n",
    "        return pd.Series([[], []])  # Empty lists if no vuln_commits\n",
    "\n",
    "# Apply the function to create new columns\n",
    "patch_vuln_df[['vuln_files', 'vuln_commits']] = patch_vuln_df['vuln_commits'].apply(extract_vuln_files_commits)\n",
    "\n",
    "\n",
    "\n",
    "print(patch_vuln_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\nimport shutil\\nfrom pydriller import Repository, Commit\\n\\n# Calculate repo size\\n    def get_directory_size(path: str, total_size: float):\\n        for dirpath, _, filenames in os.walk(path):\\n            for f in filenames:\\n                fp = os.path.join(dirpath, f)\\n                total_size += os.path.getsize(fp)\\n        return total_size\\n\\n    \\n    \\n\\n    # Optional: Delete the repo manually if needed\\n    shutil.rmtree(repo_path)\\n\\nSIZE_OF_CLONED_REPOS: list[float] = 0 ### size in MB\\nTOTAL_VULN_COMMITS_FOUND: int = 0\\nTOTAL_NOT_FOUND: int = 0\\ncount = 1\\n### Getting all the repo urls from the patch_vuln_df\\n\\nfor owner_repo in patch_vuln_df[\"repo\"]:\\n    print(\"Working on iteration: {count})\\n\\n    owner , repo = owner_repo.split(\"/\")\\n    remote_url: str = f\"https://github.com/{ownner}/{repo}.git\"\\n\\n\\n    # PyDriller clones the repo to a temporary directory\\n    temp_repo: Repository = Repository(remote_url)\\n\\n    \\n    for commit in Repository(remote_url).traverse_commits():\\n        temp_repo_path = commit.project_path  # Path to the cloned repo\\n        \\n        repo_size: float = get_directory_size(temp_repo_path, SIZE_OF_CLONED_REPOS) / (1024 * 1024)  # Convert to MB\\n    \\n\\n    count+=1\\n\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Getting the total number of vulnerability inducing commits found and the total not found!\n",
    "\n",
    "Indirectly, get the total size of the cloned repos\n",
    "\n",
    "Total size of the cloned repos\n",
    "1. Total size of repos cloned\n",
    "2. Total number of vulnerability inducing commits (vuln commits) found & not found\n",
    "3. Average number of vuln commits to patch commit (or fix)\n",
    "4. Average number of months between a vuln commit\n",
    "5. Percentage of vulns where the vuln commit and fix were made by the same person\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "'''\n",
    "import os\n",
    "import shutil\n",
    "from pydriller import Repository, Commit\n",
    "\n",
    "# Calculate repo size\n",
    "    def get_directory_size(path: str, total_size: float):\n",
    "        for dirpath, _, filenames in os.walk(path):\n",
    "            for f in filenames:\n",
    "                fp = os.path.join(dirpath, f)\n",
    "                total_size += os.path.getsize(fp)\n",
    "        return total_size\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # Optional: Delete the repo manually if needed\n",
    "    shutil.rmtree(repo_path)\n",
    "\n",
    "SIZE_OF_ALL_CLONED_REPOS: list[float] = 0 ### size in MB\n",
    "TOTAL_PATCH_COMMITS_w_VULN_COMMIT: int = 0\n",
    "TOTAL_VULN_COMMITS_FOUND: int = 0\n",
    "TOTAL_NOT_FOUND: int = 0\n",
    "\n",
    "count = 1\n",
    "### Getting all the repo urls from the patch_vuln_df\n",
    "\n",
    "for owner_repo in patch_vuln_df[\"repo\"]:\n",
    "    print(\"Working on iteration from df: {count})\n",
    "\n",
    "    # Compose remote repo for pydriller\n",
    "    owner, repo = owner_repo.split(\"/\")\n",
    "    remote_url: str = f\"https://github.com/{ownner}/{repo}.git\"\n",
    "\n",
    "\n",
    "    # PyDriller clones the repo to a temporary directory\n",
    "    temp_repo: Repository = Repository(remote_url)\n",
    "\n",
    "    \n",
    "    for commit in Repository(remote_url).traverse_commits():\n",
    "        temp_repo_path = commit.project_path  # Path to the cloned repo\n",
    "        \n",
    "        repo_size: float = get_directory_size(temp_repo_path, SIZE_OF_CLONED_REPOS) / (1024 * 1024)  # Convert to MB\n",
    "        \n",
    "        SIZE_OF_ALL_CLONED_REPOS += repo_size\n",
    "\n",
    "    count+=1\n",
    "\n",
    "### Point 2 & Point 3\n",
    "\n",
    "    \n",
    "\n",
    "AVERAGE_NUM_OF_VULNS_TO_PATCH: float = (TOTAL_VULN_COMMITS_FOUND / TAL_PATCH_COMMITS_w_VULN_COMMIT)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydriller_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
